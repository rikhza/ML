{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self,X,Y): \n",
    "        ones=np.ones(X.shape)\n",
    "        X=np.append(ones,X,axis=1)\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        self.m=X.shape[0]\n",
    "        self.n=X.shape[1]\n",
    "        self.theta=np.random.randn(X.shape[1])\n",
    "        \n",
    "    def computeCostFunction(self):\n",
    "        h=np.matmul(self.X,self.theta)\n",
    "        self.J=(1/(2*self.m))*np.sum((h-self.Y)**2)\n",
    "        return self.J\n",
    "    \n",
    "    def performGradientDescent(self,num_of_iter,alpha):\n",
    "        self.Cost_history=[]\n",
    "        self.theta_history=[]\n",
    "        for x in range(num_of_iter):\n",
    "            h=np.matmul(self.X,self.theta)\n",
    "            J=self.computeCostFunction()\n",
    "            self.Cost_history.append(J)\n",
    "            self.theta_history.append(self.theta)\n",
    "            temp=h-self.Y\n",
    "            self.theta=self.theta-(alpha/self.m)*(self.X.T.dot(temp))\n",
    "        return self.theta,self.Cost_history,self.theta_history\n",
    "            \n",
    "        \n",
    "    def predict(self,X_test,Y_test):\n",
    "        ones=np.ones(X_test.shape)\n",
    "        X_test=np.append(ones,X_test,axis=1)\n",
    "        self.Y_pred=np.matmul(X_test,self.theta)\n",
    "        self.error_percentage=(abs(self.Y_pred-Y_test)/Y_test)*100\n",
    "        return self.Y_pred,self.error_percentage\n",
    "    \n",
    "    def predictUsingNormalEquation(self,X_test,Y_test):\n",
    "        ones=np.ones(X_test.shape)\n",
    "        X_test=np.append(ones,X_test,axis=1)\n",
    "        inv=np.linalg.inv(np.matmul(self.X.T,self.X))\n",
    "        self.w=np.matmul(np.matmul(inv,self.X.T),self.Y)\n",
    "        y_pred=np.matmul(X_test,self.w)\n",
    "        return y_pred,(abs(Y_test-y_pred)/Y_test)*100\n",
    "    \n",
    "        \n",
    "    def returnTheta(self):\n",
    "        return self.theta\n",
    "    \n",
    "    def returnX(self):\n",
    "        return self.X\n",
    "        \n",
    "    def returnY(self):\n",
    "        return self.Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureScaling:\n",
    "    def __init__(self,X,y):\n",
    "        self.X=X.copy()\n",
    "        if y.ndim==1:\n",
    "            y=np.reshape(y,(y.shape[0],1))\n",
    "        self.y=y.copy()\n",
    "        self.minMax_X={}\n",
    "        self.minMax_y={}\n",
    "    \n",
    "    def fit_transform_X(self):\n",
    "        num_of_features=self.X.shape[1]\n",
    "        for i in range(num_of_features):\n",
    "            feature=self.X[:,i]\n",
    "            Mean=np.mean(feature)\n",
    "            Min=np.min(feature)\n",
    "            Max=np.max(feature)\n",
    "            feature=(feature-Mean)/(Max-Min)\n",
    "            self.minMax_X[i]=np.array([Mean,Min,Max])\n",
    "            self.X[:,i]=feature\n",
    "        return self.X.copy()\n",
    "    \n",
    "    def fit_transform_Y(self):\n",
    "        num_of_features=self.y.shape[1]\n",
    "        for i in range(num_of_features):\n",
    "            feature=self.y[:,i]\n",
    "            Mean=np.mean(feature)\n",
    "            Min=np.min(feature)\n",
    "            Max=np.max(feature)\n",
    "            feature=(feature-Mean)/(Max-Min)\n",
    "            self.minMax_y[i]=np.array([Mean,Min,Max])\n",
    "            self.y[:,i]=feature\n",
    "        return np.reshape(self.y,self.y.shape[0])\n",
    "    \n",
    "    def inverse_transform_X(self,X):\n",
    "        X_transformed=X.copy()\n",
    "        num_of_features=X_transformed.shape[1]\n",
    "        for i in range(num_of_features):\n",
    "            feature=X_transformed[:,i]\n",
    "            Mean=self.minMax_X[i][0]\n",
    "            Min=self.minMax_X[i][1]\n",
    "            Max=self.minMax_X[i][2]\n",
    "            feature=feature*(Max-Min)+Mean\n",
    "            X_transformed[:,i]=feature\n",
    "        return X_transformed\n",
    "    \n",
    "    def inverse_transform_Y(self,y):\n",
    "        y_transformed=y.copy()\n",
    "        if y_transformed.ndim==1:\n",
    "            y_transformed=np.reshape(y_transformed,(y_transformed.shape[0],1))\n",
    "        num_of_features=y_transformed.shape[1]\n",
    "        for i in range(num_of_features):\n",
    "            feature=y_transformed[:,i]\n",
    "            Mean=self.minMax_y[i][0]\n",
    "            Min=self.minMax_y[i][1]\n",
    "            Max=self.minMax_y[i][2]\n",
    "            feature=feature*(Max-Min)+Mean\n",
    "            y_transformed[:,i]=feature\n",
    "        return np.reshape(y_transformed,y_transformed.shape[0])\n",
    "    \n",
    "    def transform_X(self,X):\n",
    "        X_transformed=X.copy()\n",
    "        num_of_features=X_transformed.shape[1]\n",
    "        for i in range(num_of_features):\n",
    "            feature=X_transformed[:,i]\n",
    "            Mean=self.minMax_X[i][0]\n",
    "            Min=self.minMax_y[i][1]\n",
    "            Max=self.minMax_y[i][2]\n",
    "            feature=(feature-Mean)/(Max-Min)\n",
    "            X_transformed[:,i]=feature\n",
    "        return X_transformed\n",
    "    \n",
    "    def transform_Y(self,y):\n",
    "        y_transformed=y.copy()\n",
    "        if y_transformed.ndim==1:\n",
    "            y_transformed=np.reshape(y_transformed,(y_transformed.shape[0],1))\n",
    "        num_of_features=y_transformed.shape[1]\n",
    "        for i in range(num_of_features):\n",
    "            feature=y_transformed[:,i]\n",
    "            Mean=self.minMax_y[i][0]\n",
    "            Min=self.minMax_y[i][1]\n",
    "            Max=self.minMax_y[i][2]\n",
    "            feature=(feature-Mean)/(Max-Min)\n",
    "            y_transformed[:,i]=feature\n",
    "        return np.reshape(y_transformed,y_transformed.shape[0])\n",
    "    \n",
    "    def returnX(self):\n",
    "        return self.X\n",
    "    \n",
    "    def returnY(self):\n",
    "        return self.y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from LinearRegression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=pd.read_csv('Salary_Data.csv')\n",
    "print(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of dataset\n",
    "plt.scatter(Data.iloc[:,0:1].values,Data.iloc[:,1].values)\n",
    "plt.xlabel('Years of experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Plot of Data set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing size\n",
    "train_size=int(0.7*Data.shape[0])\n",
    "test_size=int(0.3*Data.shape[0])\n",
    "print(\"Training set size : \"+ str(train_size))\n",
    "print(\"Testing set size : \"+str(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset\n",
    "Data=Data.sample(frac=1)\n",
    "X=Data.iloc[:,0:1].values\n",
    "y=Data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeatureScaling import FeatureScaling\n",
    "fs=FeatureScaling(X,y)\n",
    "X=fs.fit_transform_X()\n",
    "y=fs.fit_transform_Y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set split\n",
    "X_train=X[0:train_size,:]\n",
    "Y_train=y[0:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing set split\n",
    "X_test=X[train_size:,:]\n",
    "Y_test=y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot of training set\n",
    "plt.scatter(X_train,Y_train)\n",
    "plt.xlabel('Years of experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Plot of training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot of testing set\n",
    "plt.scatter(X_test,Y_test)\n",
    "plt.xlabel('Years of experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Plot of testing set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta=lr.returnTheta()\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing set prediction\n",
    "y_pred_normal,error_percentage=lr.predictUsingNormalEquation(X_test,Y_test)\n",
    "y_pred_normal=fs.inverse_transform_Y(y_pred_normal)\n",
    "print(error_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set prediction\n",
    "y_pred_train_normal,error_percentage_train_normal=lr.predictUsingNormalEquation(X_train,Y_train)\n",
    "y_pred_train_normal=fs.inverse_transform_Y(y_pred_train_normal)\n",
    "print(lr.computeCostFunction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning parameters\n",
    "n_iter=1000\n",
    "alpha=0.05\n",
    "\n",
    "theta,J_Array,theta_array=lr.performGradientDescent(n_iter,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grad,ErrorPercentage=lr.predict(X_test,Y_test)\n",
    "print(ErrorPercentage)\n",
    "y_pred_grad=fs.inverse_transform_Y(y_pred_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how train set is predicted\n",
    "y_pred_train,error_for_train=lr.predict(X_train,Y_train)\n",
    "y_pred_train=fs.inverse_transform_Y(y_pred_train)\n",
    "print(error_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse scaling the features\n",
    "X_train=fs.inverse_transform_X(X_train)\n",
    "Y_train=fs.inverse_transform_Y(Y_train)\n",
    "X_test=fs.inverse_transform_X(X_test)\n",
    "Y_test=fs.inverse_transform_Y(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how train set is predicted using gradient descent\n",
    "plt.scatter(X_train,Y_train)\n",
    "plt.plot(X_train,y_pred_train,'r')\n",
    "plt.xlabel('Years of experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Training set prediction using Gradient Descent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how train set is predicted using normal equation\n",
    "plt.scatter(X_train,Y_train)\n",
    "plt.plot(X_train,y_pred_train_normal,'r')\n",
    "plt.xlabel('X_axis')\n",
    "plt.ylabel('Y_axis')\n",
    "plt.title('Training set prediction using Normal Equation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Documents\\multivariate linear regression\\Regression\\LinearRegression.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Documents/multivariate%20linear%20regression/Regression/LinearRegression.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#let's see how test set is predicted using gradient descent\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Documents/multivariate%20linear%20regression/Regression/LinearRegression.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(X_test,Y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Documents/multivariate%20linear%20regression/Regression/LinearRegression.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(X_test,y_pred_grad,\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Documents/multivariate%20linear%20regression/Regression/LinearRegression.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mX_axis\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#let's see how test set is predicted using gradient descent\n",
    "plt.scatter(X_test,Y_test)\n",
    "plt.plot(X_test,y_pred_grad,'r')\n",
    "plt.xlabel('X_axis')\n",
    "plt.ylabel('Y_axis')\n",
    "plt.title('Test set prediction using Gradient Descent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how test set is predicted using normal equation method\n",
    "plt.scatter(X_test,Y_test)\n",
    "plt.plot(X_test,y_pred_normal,'r')\n",
    "plt.xlabel('X_axis')\n",
    "plt.ylabel('Y_axis')\n",
    "plt.title('Test set prediction using Normal Equation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of how cost function is minimized as number of iterations is proceeded\n",
    "x=[i for i in range(1000)]\n",
    "plt.plot(x,J_Array)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Cost function(J)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
